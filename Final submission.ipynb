{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF-IDF + BERT + Graph.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "696nPlsn5Wyv"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "JyINv6S1EmwV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install catboost"
      ],
      "metadata": {
        "id": "Vn0lRQZA46VD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PurbJDrB43hB",
        "outputId": "9ee1c9e3-2953-4b68-8f08-a0106f7b2e18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import re\n",
        "import csv\n",
        "import gzip\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import networkx as nx\n",
        "from tqdm import tqdm\n",
        "from random import randint\n",
        "from collections import Counter\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "\n",
        "from sklearn import utils\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "import spacy\n",
        "import gensim\n",
        "from gensim.test.utils import common_texts\n",
        "from gensim.models import Doc2Vec, Word2Vec\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "\n",
        "import string\n",
        "string.punctuation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define functions and baselines"
      ],
      "metadata": {
        "id": "696nPlsn5Wyv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_dict = \\\n",
        "    {\n",
        "    'model_1': {\n",
        "        'name': 'CB',\n",
        "        'pl': CatBoostClassifier(random_seed=42, verbose=0)\n",
        "        },\n",
        "     'model_2': {\n",
        "        'name': 'XGB',\n",
        "        'pl': XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "        },\n",
        "    'model_3': {\n",
        "        'name': 'LGB',\n",
        "        'pl': LGBMClassifier(random_state=42)\n",
        "        }\n",
        "    }"
      ],
      "metadata": {
        "id": "Kvuiz-ab5YCd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "fzCYxZzk_Yrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation\n",
        "def remove_punctuation(text):\n",
        "    punctuationfree=\"\".join([i for i in text if i not in string.punctuation])\n",
        "    return punctuationfree\n",
        "\n",
        "# Tokenizer\n",
        "def tokenization(text):\n",
        "    tokens = re.split('W+',text)\n",
        "    return tokens\n",
        "\n",
        "# Lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
        "def lemmatize_words(text):\n",
        "    pos_tagged_text = nltk.pos_tag(text.split())\n",
        "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
        "\n",
        "# Remove stopwords\n",
        "STOPWORDS = set(stopwords.words('english'))\n",
        "def remove_stopwords(text):\n",
        "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])"
      ],
      "metadata": {
        "id": "HLDe2TGy5Ug_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Node2Vec embeddings"
      ],
      "metadata": {
        "id": "PIhaPdKb5irA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "G = nx.read_edgelist('data/edgelist.txt', delimiter=',', create_using=nx.Graph(), nodetype=int)\n",
        "\n",
        "nodes = list(G.nodes())\n",
        "n = G.number_of_nodes()\n",
        "m = G.number_of_edges()\n",
        "print('Number of nodes:', n)\n",
        "print('Number of edges:', m)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lMpe0jf5tHm",
        "outputId": "9f294824-0f22-425a-bd44-5addc2ddbbd8"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of nodes: 138499\n",
            "Number of edges: 1091955\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with gzip.open('embeddings/node_embeddings.emb', \"rb\") as f:\n",
        "    node_emb = pickle.load(f)"
      ],
      "metadata": {
        "id": "ZFlRhz8y5jrp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SciBERT embeddings"
      ],
      "metadata": {
        "id": "19WDYtIz5kJN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gzip.open('embeddings/abstract_embeddings.emb', \"rb\") as f:\n",
        "    bert_emb = pickle.load(f)"
      ],
      "metadata": {
        "id": "34Vsn0zy55GN"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text preprocessing"
      ],
      "metadata": {
        "id": "J4Dc-xvI6BJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "abstracts = dict()\n",
        "with open('data/abstracts.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        node, abstract = line.rstrip('\\n').split('|--|')\n",
        "        abstract = abstract.lower()\n",
        "        abstract = tokenization(remove_punctuation(abstract))[0]\n",
        "        abstract = remove_stopwords(lemmatize_words(abstract))\n",
        "        abstracts[int(node)] = abstract\n",
        "\n",
        "data = pd.DataFrame.from_dict(abstracts, orient='index', columns=['abstract'])\n",
        "data = data.replace(r'\\n',' ', regex=True)"
      ],
      "metadata": {
        "id": "PWa6qlW46CWe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "authors = dict()\n",
        "with open('data/authors.txt', 'r') as s:\n",
        "    for line in s:\n",
        "        node, author = line.rstrip(\"\\n\").split('|--|')\n",
        "        author = author.lower()\n",
        "        authors[int(node)] = author\n",
        "\n",
        "data_author = pd.DataFrame.from_dict(authors, orient='index', columns=['author'])\n",
        "data_author = data_author.replace(r'\\n',' ', regex=True)"
      ],
      "metadata": {
        "id": "GG-WE13F6IQY"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TF-IDF"
      ],
      "metadata": {
        "id": "d9kFTIc06MCO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer='char_wb', ngram_range=(3,5))\n",
        "X = vec.fit_transform(data['abstract'])\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qr8NtNpR6M_P",
        "outputId": "989cce1c-90a9-4122-ed1c-0cbcc418ce8c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<138499x196487 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 119630300 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vec = TfidfVectorizer(min_df= 3, max_df=0.5, analyzer='char_wb', ngram_range=(3,5))\n",
        "X_aut = vec.fit_transform(data_author['author'])\n",
        "X_aut"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcHInH4f6Niv",
        "outputId": "3753078b-a79a-47d8-8457-c4d55150b7cf"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<138499x238637 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 13987960 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "authors = dict()\n",
        "with open('data/authors.txt', 'r') as s:\n",
        "    for line in s:\n",
        "        node, author = line.rstrip(\"\\n\").split('|--|')\n",
        "        authors[int(node)] = author\n",
        "\n",
        "for node in authors:\n",
        "    authors[node] = set(authors[node].split(','))\n",
        "\n",
        "for node in abstracts:\n",
        "    abstracts[node] = set(abstracts[node].split())"
      ],
      "metadata": {
        "id": "G_217lOq6SHf"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create feature set"
      ],
      "metadata": {
        "id": "1fs2n3Be6P8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.zeros((2*m, 15))\n",
        "y_train = np.zeros(2*m)\n",
        "\n",
        "for i,edge in enumerate(G.edges()):\n",
        "    X_train[i, 0] = cosine_similarity(X[edge[0]], X[edge[1]])[0,0]\n",
        "    X_train[i, 1] = len(abstracts[edge[0]]) + len(abstracts[edge[1]])\n",
        "    X_train[i, 2] = abs(len(abstracts[edge[0]]) - len(abstracts[edge[1]]))\n",
        "    X_train[i, 3] = len(abstracts[edge[0]].intersection(abstracts[edge[1]]))\n",
        "    X_train[i, 4] = len(authors[edge[0]]) + len(authors[edge[1]])\n",
        "    X_train[i, 5] = abs(len(authors[edge[0]]) - len(authors[edge[1]]))\n",
        "    X_train[i, 6] = len(authors[edge[0]].intersection(authors[edge[1]]))\n",
        "    X_train[i, 7] = G.degree(edge[0]) + G.degree(edge[1])\n",
        "    X_train[i, 8] = abs(G.degree(edge[0]) - G.degree(edge[1]))\n",
        "    X_train[i, 9] = cosine_similarity(X_aut[edge[0]], X_aut[edge[1]])[0,0]\n",
        "    X_train[i, 10] = list(nx.adamic_adar_index(G, [(edge[0], edge[1])]))[0][2]\n",
        "    X_train[i, 11] = list(nx.jaccard_coefficient(G, [(edge[0], edge[1])]))[0][2]\n",
        "    X_train[i, 12] = list(nx.preferential_attachment(G, [(edge[0], edge[1])]))[0][2]\n",
        "    X_train[i, 13] = len(list(nx.common_neighbors(G, u=edge[0], v=edge[1])))\n",
        "    X_train[i, 14] = cosine_similarity(bert_emb[edge[0]], bert_emb[edge[1]])[0,0]\n",
        "    # X_train[i, 15] = cosine_similarity(node_emb[edge[0]].reshape(1, -1), node_emb[edge[1]].reshape(1, -1))[0,0]\n",
        "    y_train[i] = 1\n",
        "\n",
        "    n1 = randint(0, n-1)\n",
        "    n2 = randint(0, n-1)\n",
        "    if ( (G.has_edge(n1, n2)) ):\n",
        "        pass\n",
        "    else:\n",
        "        X_train[m+i, 0] = cosine_similarity(X[n1], X[n2])[0, 0]\n",
        "        X_train[m+i, 1] = len(abstracts[n1]) + len(abstracts[n2])\n",
        "        X_train[m+i, 2] = abs(len(abstracts[n1]) - len(abstracts[n2]))\n",
        "        X_train[m+i, 3] = len(abstracts[n1].intersection(abstracts[n2]))\n",
        "        X_train[m+i, 4] = len(authors[n1]) + len(authors[n2])\n",
        "        X_train[m+i, 5] = abs(len(authors[n1]) - len(authors[n2]))\n",
        "        X_train[m+i, 6] = len(authors[n1].intersection(authors[n2]))\n",
        "        X_train[m+i, 7] = G.degree(n1) + G.degree(n2)\n",
        "        X_train[m+i, 8] = abs(G.degree(n1) - G.degree(n2))\n",
        "        X_train[m+i, 9] = cosine_similarity(X_aut[n1], X_aut[n2])[0, 0]\n",
        "        X_train[m+i, 10] = list(nx.adamic_adar_index(G, [(n1, n2)]))[0][2]\n",
        "        X_train[m+i, 11] = list(nx.jaccard_coefficient(G, [(n1, n2)]))[0][2]\n",
        "        X_train[m+i, 12] = list(nx.preferential_attachment(G, [(n1, n2)]))[0][2]\n",
        "        X_train[m+i, 13] = len(list(nx.common_neighbors(G, u=n1, v=n2)))\n",
        "        X_train[m+i, 14] = cosine_similarity(bert_emb[n1], bert_emb[n2])[0,0]\n",
        "        # X_train[m+i, 15] = cosine_similarity(node_emb[n1].reshape(1, -1), node_emb[n2].reshape(1, -1))[0,0]\n",
        "        y_train[m+i] = 0\n",
        "\n",
        "print('Size of training matrix:', X_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u67DfXBE6fJP",
        "outputId": "70058082-a5c8-4dd9-84e1-a48ffec7288d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of training matrix: (2183910, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "node_pairs = list()\n",
        "with open('data/test.txt', 'r') as f:\n",
        "    for line in f:\n",
        "        t = line.split(',')\n",
        "        node_pairs.append((int(t[0]), int(t[1])))\n",
        "\n",
        "X_test = np.zeros((len(node_pairs), 15))\n",
        "for i,node_pair in enumerate(node_pairs):\n",
        "    X_test[i,0] = cosine_similarity(X[node_pair[0]], X[node_pair[1]])[0,0]\n",
        "    X_test[i,1] = len(abstracts[node_pair[0]]) + len(abstracts[node_pair[1]])\n",
        "    X_test[i,2] = abs(len(abstracts[node_pair[0]]) - len(abstracts[node_pair[1]]))\n",
        "    X_test[i,3] = len(abstracts[node_pair[0]].intersection(abstracts[node_pair[1]]))\n",
        "    X_test[i,4] = len(authors[node_pair[0]]) + len(authors[node_pair[1]])\n",
        "    X_test[i,5] = abs(len(authors[node_pair[0]]) - len(authors[node_pair[1]]))\n",
        "    X_test[i,6] = len(authors[node_pair[0]].intersection(authors[node_pair[1]]))\n",
        "    X_test[i,7] = G.degree(node_pair[0]) + G.degree(node_pair[1])\n",
        "    X_test[i,8] = abs(G.degree(node_pair[0]) - G.degree(node_pair[1]))\n",
        "    X_test[i,9] = cosine_similarity(X_aut[node_pair[0]], X_aut[node_pair[1]])[0,0]\n",
        "    X_test[i,10] = list(nx.adamic_adar_index(G, [(node_pair[0], node_pair[1])]))[0][2]\n",
        "    X_test[i,11] = list(nx.jaccard_coefficient(G, [(node_pair[0], node_pair[1])]))[0][2]\n",
        "    X_test[i,12] = list(nx.preferential_attachment(G, [(node_pair[0], node_pair[1])]))[0][2]\n",
        "    X_test[i,13] = len(list(nx.common_neighbors(G, u=node_pair[0], v=node_pair[1])))\n",
        "    X_test[i,14] = cosine_similarity(bert_emb[node_pair[0]], bert_emb[node_pair[1]])[0,0]\n",
        "    # X_test[i,15] = cosine_similarity(node_emb[node_pair[0]].reshape(1, -1), node_emb[node_pair[1]].reshape(1, -1))[0,0]\n",
        "\n",
        "print('Size of test matrix:', X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyCV9JJf6rLP",
        "outputId": "45645edd-4ff9-4222-f158-aaf97d2ebc9c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of test matrix: (106692, 15)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10-fold CV"
      ],
      "metadata": {
        "id": "AdAXN8Wk60IL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "l1_train = pd.DataFrame()\n",
        "l1_test = pd.DataFrame()\n",
        "\n",
        "l1_train['target'] = y_train.copy()\n",
        "l1_test['id'] = list(range(len(X_test)))\n",
        "\n",
        "for _, value in model_dict.items():\n",
        "\n",
        "    scores = []\n",
        "    n_splits=10\n",
        "    kf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
        "\n",
        "    train_preds = np.zeros(shape=(len(X_train)))\n",
        "    test_preds = np.zeros(shape=(len(X_test)))\n",
        "\n",
        "    for i, (train_idx, test_idx) in enumerate(kf.split(X_train, y_train)):\n",
        "\n",
        "        x_train, x_val = X_train[train_idx].copy(), X_train[test_idx].copy()\n",
        "        Y_train, Y_val = y_train[train_idx].copy(), y_train[test_idx].copy()\n",
        "\n",
        "        model = value['pl']\n",
        "\n",
        "        if value['name'] == 'CB' or value['name'] == 'XGB' or value['name'] == 'LGB':\n",
        "            model.fit(x_train, Y_train,\n",
        "                      eval_set=[(x_val, Y_val)],\n",
        "                      early_stopping_rounds=200,\n",
        "                      verbose=0)\n",
        "        else:\n",
        "            model.fit(x_train, Y_train)\n",
        "   \n",
        "        train_oof_preds = model.predict_proba(x_val)[:, 1]\n",
        "        train_preds[test_idx] = train_oof_preds\n",
        "\n",
        "        score = log_loss(Y_val, train_oof_preds)\n",
        "        scores.append(score)\n",
        "\n",
        "        print(f\"{value['name']}: LogLoss = {score}\")\n",
        "\n",
        "        test_oof_preds = model.predict_proba(X_test)[:, 1]\n",
        "        test_preds += test_oof_preds / n_splits\n",
        "\n",
        "    print(f\"\\n--> Overall metrics for {value['name']}\")\n",
        "    print(f\": LogLoss = {np.array(scores).mean()} +/- {np.array(scores).std()}\\n\")\n",
        "\n",
        "    l1_train[f\"{value['name']}\"] = train_preds\n",
        "    l1_test[f\"{value['name']}\"] = test_preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fj5eiAqW607t",
        "outputId": "8ba9881d-ddb9-4c02-ea18-51e6f1ca5cdf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CB: LogLoss = 0.14555364645955102\n",
            "CB: LogLoss = 0.14538328607301673\n",
            "CB: LogLoss = 0.144397953335743\n",
            "CB: LogLoss = 0.14392480853270642\n",
            "CB: LogLoss = 0.14505864545486005\n",
            "CB: LogLoss = 0.14174465088218902\n",
            "CB: LogLoss = 0.14588428508216925\n",
            "CB: LogLoss = 0.14550709020746033\n",
            "CB: LogLoss = 0.14421849928845323\n",
            "CB: LogLoss = 0.14681128657527043\n",
            "\n",
            "--> Overall metrics for CB\n",
            ": LogLoss = 0.14484841518914193 +/- 0.0013142865029192776\n",
            "\n",
            "XGB: LogLoss = 0.14897767476740134\n",
            "XGB: LogLoss = 0.1487337970404187\n",
            "XGB: LogLoss = 0.1477214528596524\n",
            "XGB: LogLoss = 0.14724232826186617\n",
            "XGB: LogLoss = 0.14829261465959784\n",
            "XGB: LogLoss = 0.14496715689474546\n",
            "XGB: LogLoss = 0.14931936320659614\n",
            "XGB: LogLoss = 0.14905735461005948\n",
            "XGB: LogLoss = 0.14760168971840315\n",
            "XGB: LogLoss = 0.14980501416380088\n",
            "\n",
            "--> Overall metrics for XGB\n",
            ": LogLoss = 0.14817184461825414 +/- 0.0013194643301604133\n",
            "\n",
            "LGB: LogLoss = 0.14644139344216175\n",
            "LGB: LogLoss = 0.14611558983057726\n",
            "LGB: LogLoss = 0.1453040989348506\n",
            "LGB: LogLoss = 0.14479974041519345\n",
            "LGB: LogLoss = 0.1456109345513995\n",
            "LGB: LogLoss = 0.1427610030230811\n",
            "LGB: LogLoss = 0.1466982979030318\n",
            "LGB: LogLoss = 0.1466429560594722\n",
            "LGB: LogLoss = 0.14510059549185492\n",
            "LGB: LogLoss = 0.14782570021898248\n",
            "\n",
            "--> Overall metrics for LGB\n",
            ": LogLoss = 0.1457300309870605 +/- 0.001307281661237417\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Meta-model"
      ],
      "metadata": {
        "id": "d9VddB2t63bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scores = []\n",
        "n_splits=10\n",
        "kf = StratifiedKFold(n_splits=n_splits, random_state=42, shuffle=True)\n",
        "\n",
        "train_preds = np.zeros(shape=(len(l1_train.index)))\n",
        "test_preds = np.zeros(shape=(len(l1_test.index)))\n",
        "\n",
        "features = l1_test.columns.to_list()[1:]\n",
        "y = l1_train['target'].copy()\n",
        "\n",
        "for i, (train_idx, test_idx) in enumerate(kf.split(l1_train, y)):\n",
        "\n",
        "    x_train, x_val = l1_train[features].iloc[train_idx].copy(), l1_train[features].iloc[test_idx].copy()\n",
        "    y_train, y_val = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
        "\n",
        "    model =  LinearRegression()\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    train_oof_preds = model.predict(x_val)\n",
        "    train_preds[test_idx] = train_oof_preds\n",
        "\n",
        "    score = log_loss(y_val, train_oof_preds)\n",
        "    scores.append(score)\n",
        "\n",
        "    print(f\"LR : LogLoss = {score}\")\n",
        "\n",
        "    test_oof_preds = model.predict(l1_test[features])\n",
        "    test_preds += test_oof_preds / n_splits\n",
        "\n",
        "print(f\"\\n--> Overall metrics for LR\")\n",
        "print(f\": LogLoss = {np.array(scores).mean()} +/- {np.array(scores).std()}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-IKED9U64LY",
        "outputId": "54055328-30b3-4228-c7e6-0673d8f8be53"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR : LogLoss = 0.14547154025271317\n",
            "LR : LogLoss = 0.14529648419957247\n",
            "LR : LogLoss = 0.14430923423082653\n",
            "LR : LogLoss = 0.14382606197346118\n",
            "LR : LogLoss = 0.1449224041456537\n",
            "LR : LogLoss = 0.1416825930786438\n",
            "LR : LogLoss = 0.1458792759771605\n",
            "LR : LogLoss = 0.14545530169712725\n",
            "LR : LogLoss = 0.14425735636904863\n",
            "LR : LogLoss = 0.14681020646917525\n",
            "\n",
            "--> Overall metrics for LR\n",
            ": LogLoss = 0.14479104583933824 +/- 0.0013247235642763662\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get submission"
      ],
      "metadata": {
        "id": "NIzLOJBE65to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sub = pd.DataFrame()\n",
        "sub['id'] = list(range(len(X_test)))\n",
        "sub['predicted'] = test_preds\n",
        "\n",
        "sub.to_csv('submission.csv', index=False)\n",
        "\n",
        "sub.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "C9r1_gbE66n7",
        "outputId": "1c7d927d-605c-4131-a13a-6291a6c572ff"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id  predicted\n",
              "0   0   0.996897\n",
              "1   1   0.083376\n",
              "2   2   0.738238\n",
              "3   3   0.267565\n",
              "4   4   0.079678"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27a8e082-5627-4a98-aa6a-696b1ae5bc33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.996897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.083376</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.738238</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.267565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.079678</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27a8e082-5627-4a98-aa6a-696b1ae5bc33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-27a8e082-5627-4a98-aa6a-696b1ae5bc33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-27a8e082-5627-4a98-aa6a-696b1ae5bc33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}